# GraphRAG éƒ¨ç½²æ¨¡å¼èˆ‡ä½¿ç”¨èªªæ˜

## ğŸ“¦ éƒ¨ç½²æ¨¡å¼æ¦‚è¦½

GraphRAG æ¡ç”¨ **å¥—ä»¶åˆ†ç™¼æ¨¡å¼**ï¼Œè€Œéå‚³çµ±çš„ SaaS æˆ–å®¹å™¨åŒ–éƒ¨ç½²ã€‚ä½¿ç”¨è€…éœ€è¦è‡ªè¡Œå®‰è£å¥—ä»¶ä¸¦é…ç½®ç›¸é—œæœå‹™ã€‚

## ğŸ”„ å®Œæ•´ä½¿ç”¨æµç¨‹

### éšæ®µ 1: å®‰è£å¥—ä»¶

#### ä½¿ç”¨ pip å®‰è£
```bash
pip install graphrag
```

#### ä½¿ç”¨ Poetry å®‰è£
```bash
poetry add graphrag
```

#### é©—è­‰å®‰è£
```bash
graphrag --help
```

### éšæ®µ 2: ç’°å¢ƒæº–å‚™

#### 2.1 æº–å‚™ LLM æœå‹™
é¸æ“‡ä»¥ä¸‹å…¶ä¸­ä¸€ç¨®ï¼š

**é¸é … A: OpenAI API**
```bash
export GRAPHRAG_API_KEY="your-openai-api-key"
export GRAPHRAG_LLM_TYPE="openai_chat"
export GRAPHRAG_EMBEDDING_TYPE="openai_embedding"
```

**é¸é … B: Azure OpenAI**
```bash
export GRAPHRAG_API_KEY="your-azure-openai-key"
export GRAPHRAG_API_BASE="https://your-resource.openai.azure.com"
export GRAPHRAG_API_VERSION="2024-02-15-preview"
export GRAPHRAG_LLM_TYPE="azure_openai_chat"
export GRAPHRAG_EMBEDDING_TYPE="azure_openai_embedding"
```

#### 2.2 æº–å‚™å‘é‡å„²å­˜
é¸æ“‡ä»¥ä¸‹å…¶ä¸­ä¸€ç¨®ï¼š

**é¸é … A: Azure AI Search**
```bash
export AZURE_AI_SEARCH_URL_ENDPOINT="https://your-search-service.search.windows.net"
export AZURE_AI_SEARCH_API_KEY="your-search-api-key"
```

**é¸é … B: LanceDB (æœ¬åœ°)**
```bash
# ç„¡éœ€é¡å¤–é…ç½®ï¼Œæœƒè‡ªå‹•ä½¿ç”¨æœ¬åœ°æª”æ¡ˆ
```

### éšæ®µ 3: å°ˆæ¡ˆåˆå§‹åŒ–

#### 3.1 å»ºç«‹å°ˆæ¡ˆç›®éŒ„
```bash
mkdir my-graphrag-project
cd my-graphrag-project
```

#### 3.2 åˆå§‹åŒ– GraphRAG
```bash
graphrag init --root .
```

é€™æœƒå»ºç«‹ä»¥ä¸‹çµæ§‹ï¼š
```
my-graphrag-project/
â”œâ”€â”€ settings.yaml          # ä¸»è¦é…ç½®æª”
â”œâ”€â”€ .env                   # ç’°å¢ƒè®Šæ•¸
â”œâ”€â”€ input/                 # è¼¸å…¥æ–‡ä»¶ç›®éŒ„
â”œâ”€â”€ output/                # è¼¸å‡ºçµæœç›®éŒ„
â””â”€â”€ prompts/              # è‡ªå®šç¾©æç¤ºè©
```

#### 3.3 é…ç½® settings.yaml
```yaml
llm:
  api_key: ${GRAPHRAG_API_KEY}
  type: azure_openai_chat
  model: gpt-4
  api_base: ${GRAPHRAG_API_BASE}
  api_version: ${GRAPHRAG_API_VERSION}

embeddings:
  api_key: ${GRAPHRAG_API_KEY}
  type: azure_openai_embedding
  model: text-embedding-ada-002
  api_base: ${GRAPHRAG_API_BASE}

vector_store:
  type: azure_ai_search
  url: ${AZURE_AI_SEARCH_URL_ENDPOINT}
  api_key: ${AZURE_AI_SEARCH_API_KEY}

input:
  type: file
  file_type: text
  base_dir: "input"

storage:
  type: file
  base_dir: "output"
```

### éšæ®µ 4: è³‡æ–™è™•ç†

#### 4.1 æº–å‚™è¼¸å…¥è³‡æ–™
å°‡æ–‡ä»¶æ”¾å…¥ `input/` ç›®éŒ„ï¼š
```bash
cp your-documents.txt input/
```

#### 4.2 åŸ·è¡Œç´¢å¼•å»ºç«‹
```bash
graphrag index --root .
```

é€™å€‹éç¨‹æœƒï¼š
- åˆ†ææ–‡ä»¶å…§å®¹
- æŠ½å–å¯¦é«”å’Œé—œä¿‚
- å»ºç«‹çŸ¥è­˜åœ–è­œ
- ç”Ÿæˆå‘é‡åµŒå…¥
- å„²å­˜åˆ°æŒ‡å®šçš„å‘é‡è³‡æ–™åº«

#### 4.3 ç›£æ§é€²åº¦
```bash
# æŸ¥çœ‹è¼¸å‡ºç›®éŒ„
ls -la output/

# æŸ¥çœ‹æ—¥èªŒ
tail -f output/indexing-engine.log
```

### éšæ®µ 5: æŸ¥è©¢ä½¿ç”¨

#### 5.1 å…¨åŸŸæŸ¥è©¢ (Global Search)
```bash
graphrag query --root . --method global "ä»€éº¼æ˜¯é€™äº›æ–‡ä»¶çš„ä¸»è¦ä¸»é¡Œï¼Ÿ"
```

#### 5.2 å±€éƒ¨æŸ¥è©¢ (Local Search)
```bash
graphrag query --root . --method local "æ‰¾å‡ºèˆ‡ç‰¹å®šå¯¦é«”ç›¸é—œçš„è³‡è¨Š"
```

#### 5.3 ç¨‹å¼åŒ–ä½¿ç”¨
```python
from graphrag.query.factories import get_global_search_engine

# è¼‰å…¥é…ç½®
config = load_config("./settings.yaml")

# å»ºç«‹æœå°‹å¼•æ“
search_engine = get_global_search_engine(config)

# åŸ·è¡ŒæŸ¥è©¢
result = search_engine.search("ä½ çš„å•é¡Œ")
print(result.response)
```

## ğŸ”§ é€²éšé…ç½®

### è‡ªå®šç¾©æç¤ºè©
```bash
# ç”Ÿæˆæç¤ºè©æ¨¡æ¿
graphrag prompt-tune --root . --config settings.yaml

# ç·¨è¼¯ç”Ÿæˆçš„æç¤ºè©
vim prompts/entity_extraction.txt
```

### æ•ˆèƒ½èª¿å„ª
```yaml
# settings.yaml ä¸­çš„æ•ˆèƒ½è¨­å®š
parallelization:
  stagger: 0.3
  num_threads: 4

chunk_size: 1200
chunk_overlap: 100

llm:
  max_tokens: 4000
  temperature: 0.0
```

### å¿«å–é…ç½®
```yaml
cache:
  type: file
  base_dir: "cache"
  
# æˆ–ä½¿ç”¨ Azure Blob Storage
cache:
  type: blob
  connection_string: ${AZURE_STORAGE_CONNECTION_STRING}
  container_name: "graphrag-cache"
```

## ğŸš¨ å¸¸è¦‹å•é¡Œèˆ‡è§£æ±ºæ–¹æ¡ˆ

### å•é¡Œ 1: API é…é¡é™åˆ¶
```bash
# èª¿æ•´é€Ÿç‡é™åˆ¶
export GRAPHRAG_LLM_TPM=60000  # Tokens per minute
export GRAPHRAG_LLM_RPM=1000   # Requests per minute
```

### å•é¡Œ 2: è¨˜æ†¶é«”ä¸è¶³
```yaml
# æ¸›å°‘ä¸¦è¡Œè™•ç†
parallelization:
  num_threads: 2
  
# æ¸›å°‘å€å¡Šå¤§å°
chunk_size: 800
```

### å•é¡Œ 3: ç¶²è·¯é€£ç·šå•é¡Œ
```yaml
# å¢åŠ é‡è©¦è¨­å®š
llm:
  max_retries: 5
  retry_delay: 2.0
```

## ğŸ“Š æˆæœ¬ä¼°ç®—

### OpenAI API æˆæœ¬ (ä¼°ç®—)
- **GPT-4**: ~$0.03/1K tokens
- **Embedding**: ~$0.0001/1K tokens
- **1MB æ–‡ä»¶**: ç´„ $5-15 USD

### Azure æœå‹™æˆæœ¬
- **Azure OpenAI**: æŒ‰ä½¿ç”¨é‡è¨ˆè²»
- **Azure AI Search**: åŸºæœ¬å±¤ ~$250/æœˆ
- **Azure Storage**: ~$0.02/GB/æœˆ

## ğŸ”’ å®‰å…¨æ€§å»ºè­°

### API é‡‘é‘°ç®¡ç†
```bash
# ä½¿ç”¨ .env æª”æ¡ˆ
echo "GRAPHRAG_API_KEY=your-key" >> .env
echo ".env" >> .gitignore
```

### è³‡æ–™éš±ç§
- æ•æ„Ÿè³‡æ–™å»ºè­°ä½¿ç”¨æœ¬åœ° LanceDB
- è€ƒæ…®ä½¿ç”¨ Azure Private Endpoints
- å®šæœŸæ¸…ç†å¿«å–å’Œæš«å­˜æª”æ¡ˆ

### å­˜å–æ§åˆ¶
```yaml
# é™åˆ¶æª”æ¡ˆå­˜å–æ¬Šé™
chmod 600 .env
chmod 600 settings.yaml
```

## ğŸ“ˆ ç›£æ§èˆ‡ç¶­é‹

### æ—¥èªŒç›£æ§
```bash
# å•Ÿç”¨è©³ç´°æ—¥èªŒ
export GRAPHRAG_LOG_LEVEL=DEBUG

# æŸ¥çœ‹å³æ™‚æ—¥èªŒ
tail -f output/indexing-engine.log
```

### æ•ˆèƒ½ç›£æ§
```python
import time
from graphrag.index.api import build_index

start_time = time.time()
build_index(config)
print(f"ç´¢å¼•å»ºç«‹è€—æ™‚: {time.time() - start_time:.2f} ç§’")
```

### å®šæœŸç¶­è­·
```bash
# æ¸…ç†èˆŠå¿«å–
find cache/ -type f -mtime +7 -delete

# å‚™ä»½é‡è¦é…ç½®
cp settings.yaml settings.yaml.backup
```

é€™ä»½æ–‡ä»¶æä¾›äº† GraphRAG å¾å®‰è£åˆ°ä½¿ç”¨çš„å®Œæ•´æŒ‡å—ï¼Œå¹«åŠ©ä½¿ç”¨è€…ç†è§£å¥—ä»¶åˆ†ç™¼æ¨¡å¼çš„ç‰¹é»å’Œä½¿ç”¨æ–¹å¼ã€‚
