# GraphRAG æ•…éšœæ’é™¤æŒ‡å—

## ğŸš¨ å¸¸è¦‹å•é¡Œèˆ‡è§£æ±ºæ–¹æ¡ˆ

### 1. å®‰è£ç›¸é—œå•é¡Œ

#### å•é¡Œï¼šPoetry å®‰è£å¤±æ•—
```bash
# éŒ¯èª¤è¨Šæ¯
ERROR: Could not find a version that satisfies the requirement graphrag

# è§£æ±ºæ–¹æ¡ˆ
# 1. æ›´æ–° pip å’Œ poetry
pip install --upgrade pip
poetry self update

# 2. æ¸…é™¤å¿«å–
poetry cache clear pypi --all
pip cache purge

# 3. ä½¿ç”¨ç‰¹å®š Python ç‰ˆæœ¬
poetry env use python3.10
```

#### å•é¡Œï¼šä¾è³´è¡çª
```bash
# éŒ¯èª¤è¨Šæ¯
The current project's Python requirement (>=3.10,<3.13) is not compatible

# è§£æ±ºæ–¹æ¡ˆ
# 1. æª¢æŸ¥ Python ç‰ˆæœ¬
python --version

# 2. å»ºç«‹è™›æ“¬ç’°å¢ƒ
python3.10 -m venv graphrag-env
source graphrag-env/bin/activate  # Linux/Mac
# æˆ–
graphrag-env\Scripts\activate     # Windows

# 3. é‡æ–°å®‰è£
pip install graphrag
```

### 2. é…ç½®ç›¸é—œå•é¡Œ

#### å•é¡Œï¼šAPI é‡‘é‘°ç„¡æ•ˆ
```bash
# éŒ¯èª¤è¨Šæ¯
AuthenticationError: Invalid API key provided

# è§£æ±ºæ–¹æ¡ˆ
# 1. æª¢æŸ¥ç’°å¢ƒè®Šæ•¸
echo $GRAPHRAG_API_KEY

# 2. é©—è­‰ API é‡‘é‘°æ ¼å¼
# OpenAI: sk-...
# Azure: 32 å­—å…ƒçš„åå…­é€²ä½å­—ä¸²

# 3. æ¸¬è©¦ API é€£ç·š
curl -H "Authorization: Bearer $GRAPHRAG_API_KEY" \
     https://api.openai.com/v1/models
```

#### å•é¡Œï¼šAzure OpenAI é…ç½®éŒ¯èª¤
```bash
# éŒ¯èª¤è¨Šæ¯
InvalidRequestError: The API deployment for this resource does not exist

# è§£æ±ºæ–¹æ¡ˆ
# 1. æª¢æŸ¥éƒ¨ç½²åç¨±
az cognitiveservices account deployment list \
   --name your-openai-resource \
   --resource-group your-rg

# 2. é©—è­‰ API ç‰ˆæœ¬
export GRAPHRAG_API_VERSION="2024-02-15-preview"

# 3. æª¢æŸ¥ç«¯é»æ ¼å¼
export GRAPHRAG_API_BASE="https://your-resource.openai.azure.com"
```

#### å•é¡Œï¼šå‘é‡å„²å­˜é€£ç·šå¤±æ•—
```bash
# éŒ¯èª¤è¨Šæ¯ (Azure AI Search)
ServiceRequestError: The request failed due to a client error

# è§£æ±ºæ–¹æ¡ˆ
# 1. æª¢æŸ¥æœå°‹æœå‹™ç‹€æ…‹
az search service show --name your-search-service --resource-group your-rg

# 2. é©—è­‰ API é‡‘é‘°
curl -H "api-key: $AZURE_AI_SEARCH_API_KEY" \
     "$AZURE_AI_SEARCH_URL_ENDPOINT/indexes?api-version=2023-11-01"

# 3. æª¢æŸ¥é˜²ç«ç‰†è¨­å®š
# ç¢ºä¿å…è¨±ä¾†è‡ªåŸ·è¡Œç’°å¢ƒçš„ IP å­˜å–
```

### 3. ç´¢å¼•å»ºç«‹å•é¡Œ

#### å•é¡Œï¼šè¨˜æ†¶é«”ä¸è¶³
```bash
# éŒ¯èª¤è¨Šæ¯
MemoryError: Unable to allocate array

# è§£æ±ºæ–¹æ¡ˆ
# 1. æ¸›å°‘ä¸¦è¡Œè™•ç†
# settings.yaml
parallelization:
  num_threads: 2
  stagger: 1.0

# 2. æ¸›å°‘å€å¡Šå¤§å°
chunks:
  size: 800
  overlap: 50

# 3. ä½¿ç”¨åˆ†æ‰¹è™•ç†
# å°‡å¤§æª”æ¡ˆåˆ†å‰²æˆå°æª”æ¡ˆè™•ç†
```

#### å•é¡Œï¼šAPI é…é¡è¶…é™
```bash
# éŒ¯èª¤è¨Šæ¯
RateLimitError: Rate limit reached for requests

# è§£æ±ºæ–¹æ¡ˆ
# 1. èª¿æ•´é€Ÿç‡é™åˆ¶
export GRAPHRAG_LLM_TPM=30000    # é™ä½ TPM
export GRAPHRAG_LLM_RPM=500      # é™ä½ RPM

# 2. å¢åŠ å»¶é²
# settings.yaml
parallelization:
  stagger: 2.0  # å¢åŠ å»¶é²æ™‚é–“

# 3. æ¸›å°‘ä¸¦è¡Œè«‹æ±‚
llm:
  concurrent_requests: 2
```

#### å•é¡Œï¼šæ–‡ä»¶ç·¨ç¢¼éŒ¯èª¤
```bash
# éŒ¯èª¤è¨Šæ¯
UnicodeDecodeError: 'utf-8' codec can't decode byte

# è§£æ±ºæ–¹æ¡ˆ
# 1. æª¢æŸ¥æª”æ¡ˆç·¨ç¢¼
file -I input/*.txt

# 2. è½‰æ›ç·¨ç¢¼
iconv -f big5 -t utf-8 input/file.txt > input/file_utf8.txt

# 3. è¨­å®šæ­£ç¢ºç·¨ç¢¼
# settings.yaml
input:
  file_encoding: "big5"  # æˆ–å…¶ä»–ç·¨ç¢¼
```

### 4. æŸ¥è©¢ç›¸é—œå•é¡Œ

#### å•é¡Œï¼šæŸ¥è©¢çµæœç‚ºç©º
```bash
# å¯èƒ½åŸå› èˆ‡è§£æ±ºæ–¹æ¡ˆ

# 1. æª¢æŸ¥ç´¢å¼•æ˜¯å¦å®Œæˆ
ls -la output/
# æ‡‰è©²çœ‹åˆ° entities.parquet, relationships.parquet ç­‰æª”æ¡ˆ

# 2. æª¢æŸ¥å‘é‡å„²å­˜
# Azure AI Search
curl -H "api-key: $AZURE_AI_SEARCH_API_KEY" \
     "$AZURE_AI_SEARCH_URL_ENDPOINT/indexes/graphrag-index/docs/\$count?api-version=2023-11-01"

# 3. èª¿æ•´æŸ¥è©¢åƒæ•¸
graphrag query --root . --method global \
  --community-level 2 \
  --response-type "Multiple Paragraphs" \
  "your question"
```

#### å•é¡Œï¼šæŸ¥è©¢å›æ‡‰å“è³ªå·®
```bash
# è§£æ±ºæ–¹æ¡ˆ

# 1. èª¿æ•´ç¤¾ç¾¤å±¤ç´š
graphrag query --root . --method global \
  --community-level 1  # å˜—è©¦ä¸åŒå±¤ç´š 0-3

# 2. ä½¿ç”¨å±€éƒ¨æœå°‹
graphrag query --root . --method local \
  "specific entity or topic"

# 3. å„ªåŒ–æç¤ºè©
graphrag prompt-tune --root . --config settings.yaml
# ç·¨è¼¯ç”Ÿæˆçš„æç¤ºè©æª”æ¡ˆ
```

### 5. æ•ˆèƒ½å•é¡Œ

#### å•é¡Œï¼šç´¢å¼•å»ºç«‹å¤ªæ…¢
```bash
# å„ªåŒ–æ–¹æ¡ˆ

# 1. å¢åŠ ä¸¦è¡Œè™•ç†
# settings.yaml
parallelization:
  num_threads: 8  # æ ¹æ“š CPU æ ¸å¿ƒæ•¸èª¿æ•´

# 2. ä½¿ç”¨æ›´å¿«çš„ LLM
llm:
  model: gpt-3.5-turbo  # æ¯” gpt-4 æ›´å¿«

# 3. å•Ÿç”¨å¿«å–
cache:
  type: file
  base_dir: "cache"
```

#### å•é¡Œï¼šæŸ¥è©¢å›æ‡‰å¤ªæ…¢
```bash
# å„ªåŒ–æ–¹æ¡ˆ

# 1. ä½¿ç”¨æœ¬åœ°å‘é‡å„²å­˜
vector_store:
  type: lancedb
  db_uri: "./lancedb"

# 2. èª¿æ•´æœå°‹åƒæ•¸
# æ¸›å°‘æª¢ç´¢çš„æ–‡ä»¶æ•¸é‡

# 3. ä½¿ç”¨æ›´å¿«çš„åµŒå…¥æ¨¡å‹
embeddings:
  model: text-embedding-3-small  # æ›´å¿«çš„æ¨¡å‹
```

### 6. å„²å­˜ç›¸é—œå•é¡Œ

#### å•é¡Œï¼šAzure Blob Storage å­˜å–éŒ¯èª¤
```bash
# éŒ¯èª¤è¨Šæ¯
BlobServiceError: The specified container does not exist

# è§£æ±ºæ–¹æ¡ˆ
# 1. å»ºç«‹å®¹å™¨
az storage container create \
  --name graphrag-output \
  --connection-string "$AZURE_STORAGE_CONNECTION_STRING"

# 2. æª¢æŸ¥æ¬Šé™
az storage container show \
  --name graphrag-output \
  --connection-string "$AZURE_STORAGE_CONNECTION_STRING"

# 3. é©—è­‰é€£ç·šå­—ä¸²æ ¼å¼
echo $AZURE_STORAGE_CONNECTION_STRING
```

#### å•é¡Œï¼šæœ¬åœ°æª”æ¡ˆæ¬Šé™éŒ¯èª¤
```bash
# éŒ¯èª¤è¨Šæ¯
PermissionError: [Errno 13] Permission denied

# è§£æ±ºæ–¹æ¡ˆ
# 1. æª¢æŸ¥ç›®éŒ„æ¬Šé™
ls -la output/

# 2. ä¿®æ­£æ¬Šé™
chmod 755 output/
chmod 644 output/*

# 3. æª¢æŸ¥ç£ç¢Ÿç©ºé–“
df -h .
```

### 7. é™¤éŒ¯å·¥å…·èˆ‡æŠ€å·§

#### å•Ÿç”¨è©³ç´°æ—¥èªŒ
```bash
# è¨­å®šæ—¥èªŒç­‰ç´š
export GRAPHRAG_LOG_LEVEL=DEBUG

# æŸ¥çœ‹å³æ™‚æ—¥èªŒ
tail -f output/indexing-engine.log

# æœå°‹ç‰¹å®šéŒ¯èª¤
grep -i error output/indexing-engine.log
```

#### é…ç½®é©—è­‰
```bash
# é©—è­‰é…ç½®æª”æ¡ˆ
python -c "
import yaml
with open('settings.yaml') as f:
    config = yaml.safe_load(f)
    print('é…ç½®æª”æ¡ˆèªæ³•æ­£ç¢º')
"

# æ¸¬è©¦ç’°å¢ƒè®Šæ•¸
python -c "
import os
print('API Key:', os.getenv('GRAPHRAG_API_KEY', 'Not Set'))
print('API Base:', os.getenv('GRAPHRAG_API_BASE', 'Not Set'))
"
```

#### åˆ†æ­¥é™¤éŒ¯
```bash
# 1. æ¸¬è©¦ LLM é€£ç·š
python -c "
from graphrag.llm.openai import create_openai_chat_llm
llm = create_openai_chat_llm(api_key='your-key')
print('LLM é€£ç·šæˆåŠŸ')
"

# 2. æ¸¬è©¦å‘é‡å„²å­˜
python -c "
from graphrag.vector_stores import VectorStoreFactory
vs = VectorStoreFactory.create_vector_store(config)
print('å‘é‡å„²å­˜é€£ç·šæˆåŠŸ')
"

# 3. æ¸¬è©¦æª”æ¡ˆè®€å–
python -c "
import os
files = os.listdir('input/')
print(f'æ‰¾åˆ° {len(files)} å€‹è¼¸å…¥æª”æ¡ˆ')
"
```

### 8. æ•ˆèƒ½ç›£æ§

#### ç›£æ§è³‡æºä½¿ç”¨
```bash
# CPU å’Œè¨˜æ†¶é«”ç›£æ§
top -p $(pgrep -f graphrag)

# ç£ç¢Ÿ I/O ç›£æ§
iotop -p $(pgrep -f graphrag)

# ç¶²è·¯ç›£æ§
netstat -i
```

#### ç›£æ§ API ä½¿ç”¨
```bash
# è¨˜éŒ„ API å‘¼å«
export GRAPHRAG_LOG_LEVEL=DEBUG
grep -i "api" output/indexing-engine.log | wc -l

# è¨ˆç®—æˆæœ¬
python -c "
import re
with open('output/indexing-engine.log') as f:
    content = f.read()
    tokens = re.findall(r'tokens: (\d+)', content)
    total = sum(int(t) for t in tokens)
    print(f'ç¸½ Token ä½¿ç”¨é‡: {total:,}')
"
```

é€™ä»½æ•…éšœæ’é™¤æŒ‡å—æ¶µè“‹äº† GraphRAG ä½¿ç”¨éç¨‹ä¸­æœ€å¸¸è¦‹çš„å•é¡Œå’Œè§£æ±ºæ–¹æ¡ˆï¼Œå¹«åŠ©ä½¿ç”¨è€…å¿«é€Ÿè¨ºæ–·å’Œè§£æ±ºå•é¡Œã€‚
