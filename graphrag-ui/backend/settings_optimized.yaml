# GraphRAG 中文優化配置 - 最終版本
# 基於日誌分析 + 外部最佳實踐 + tokenizer 問題修復

llm:
  type: openai_chat
  api_base: http://localhost:1234/v1
  api_key: lm-studio
  model: qwen/qwen3-vl-8b
  max_tokens: 1500  # 適中設置，避免過長回應
  temperature: 0.0
  request_timeout: 1200.0  # 20 分鐘超時
  max_retries: 1  # 最小化無效重試
  concurrent_requests: 1  # 完全序列化

embeddings:
  llm:
    type: openai_embedding
    api_base: http://localhost:1234/v1
    api_key: lm-studio
    model: nomic-embed-text-v1.5
    request_timeout: 300.0  # embedding 相對較快
    max_retries: 2

# 文本處理優化
chunks:
  size: 250  # 進一步縮小，確保穩定性
  overlap: 50  # 適當重疊

input:
  type: file
  file_type: text
  base_dir: input
  file_pattern: ".*\\.txt$"
  encoding: utf-8  # 明確指定 UTF-8

cache:
  type: file
  base_dir: cache

storage:
  type: file
  base_dir: output

# 實體提取優化
entity_extraction:
  max_gleanings: 0  # 禁用 gleaning，避免無限循環
  prompt: |
    請從以下中文文本中提取實體和關係。
    使用中文回應，保持原始格式。
    
# 完全序列化處理
parallelization:
  stagger: 3.0  # 3 秒間隔，給模型充分恢復時間
  num_threads: 1  # 單線程處理

# 禁用非必要功能
claim_extraction:
  enabled: false

community_reports:
  enabled: false

summarize_descriptions:
  enabled: false

# 日誌優化
reporting:
  type: file
  base_dir: output
