# Phase 3: æ•ˆèƒ½å„ªåŒ–æ¨¡çµ„

## ç¸½è¦½

Phase 3 å„ªåŒ–æ¨¡çµ„æä¾›æ™ºèƒ½å¿«å–ã€æ‰¹æ¬¡è™•ç†å’Œæ•ˆèƒ½ç›£æ§åŠŸèƒ½ï¼Œæ—¨åœ¨å°‡ GraphRAG ç´¢å¼•éç¨‹ä¸­çš„ LLM èª¿ç”¨æ¬¡æ•¸æ¸›å°‘ 30% ä»¥ä¸Šï¼Œä¸¦å¤§å¹…æå‡è™•ç†æ•ˆç‡ã€‚

## æ¨¡çµ„çµæ§‹

```
optimization/
â”œâ”€â”€ __init__.py                  # æ¨¡çµ„å°å‡º
â”œâ”€â”€ cache_manager.py            # æ™ºèƒ½å¿«å–ç³»çµ±
â”œâ”€â”€ batch_processor.py          # æ‰¹æ¬¡è™•ç†é‚è¼¯
â”œâ”€â”€ performance_monitor.py      # æ•ˆèƒ½ç›£æ§å·¥å…·
â””â”€â”€ README.md                   # æœ¬æ–‡æª”
```

## æ ¸å¿ƒçµ„ä»¶

### 1. cache_manager.py - æ™ºèƒ½å¿«å–ç³»çµ±

æä¾›ä¸‰ç¨®å¿«å–å¯¦ç¾ï¼š

#### HashBasedCache
- **ç”¨é€”**: åŸºæ–¼å…§å®¹é›œæ¹Šçš„é€šç”¨å¿«å–
- **ç‰¹é»**: SQLite æŒä¹…åŒ–ã€TTL æ”¯æŒã€è‡ªå‹•æ·˜æ±°
- **é©ç”¨**: é€šç”¨ LLM çµæœå¿«å–

```python
cache = HashBasedCache(
    cache_dir=".cache/graphrag",
    ttl_seconds=None,      # æ°¸ä¸éæœŸ
    max_size_mb=500,       # æœ€å¤§ 500MB
)
```

#### MultiLevelCache
- **ç”¨é€”**: é›™å±¤å¿«å–ï¼ˆè¨˜æ†¶é«” + ç£ç¢Ÿï¼‰
- **ç‰¹é»**: L1 LRU è¨˜æ†¶é«”å¿«å– + L2 æŒä¹…åŒ–å¿«å–
- **é©ç”¨**: é«˜é »è¨ªå•å ´æ™¯

```python
cache = MultiLevelCache(
    l1_max_entries=1000,   # L1 è¨˜æ†¶é«”å®¹é‡
    l2_max_size_mb=500,    # L2 ç£ç¢Ÿå®¹é‡
)
```

#### EntityRelationshipCache
- **ç”¨é€”**: å¯¦é«”é—œä¿‚æå–å°ˆç”¨å¿«å–
- **ç‰¹é»**: é‡å° GraphRAG å¯¦é«”æå–å„ªåŒ–
- **é©ç”¨**: å¯¦é«”å’Œé—œä¿‚æå–ä»»å‹™

```python
er_cache = EntityRelationshipCache(
    cache_dir=".cache/entities"
)
entities = er_cache.get_entities(text, prompt)
```

### 2. batch_processor.py - æ‰¹æ¬¡è™•ç†é‚è¼¯

æä¾›å¤šç¨®æ‰¹æ¬¡è™•ç†ç­–ç•¥ï¼š

#### BatchProcessor
- **åŸºç¤æ‰¹æ¬¡è™•ç†å™¨**
- ç´¯ç©è«‹æ±‚ä¸¦æ‰¹æ¬¡è™•ç†
- å¯é…ç½®æ‰¹æ¬¡å¤§å°å’Œç­‰å¾…æ™‚é–“

#### AdaptiveBatchProcessor
- **è‡ªé©æ‡‰æ‰¹æ¬¡è™•ç†å™¨**
- åŸºæ–¼æ€§èƒ½å‹•æ…‹èª¿æ•´æ‰¹æ¬¡å¤§å°
- è‡ªå‹•å„ªåŒ–ååé‡

#### DedupBatchProcessor
- **å»é‡æ‰¹æ¬¡è™•ç†å™¨**
- è­˜åˆ¥ä¸¦å»é™¤æ‰¹æ¬¡å…§é‡è¤‡é …
- æ¯å€‹å”¯ä¸€è¼¸å…¥åªè™•ç†ä¸€æ¬¡

#### TextChunkBatcher
- **æ–‡æœ¬åˆ†å¡Šæ‰¹æ¬¡è™•ç†å™¨**
- Token æ„ŸçŸ¥çš„æ‰¹æ¬¡å‰µå»º
- éµå®ˆæ¨¡å‹ token é™åˆ¶

### 3. performance_monitor.py - æ•ˆèƒ½ç›£æ§å·¥å…·

#### PerformanceMonitor
- **å…¨é¢æ•ˆèƒ½è¿½è¹¤**
- è¨˜éŒ„æ™‚é–“ã€èª¿ç”¨æ¬¡æ•¸ã€å¿«å–å‘½ä¸­ç‡
- è¨ˆç®—æ•ˆç‡æŒ‡æ¨™
- å°å‡ºè©³ç´°å ±å‘Š

```python
monitor = PerformanceMonitor()

with monitor.track("entity_extraction"):
    extract_entities(text)

monitor.record_llm_call(duration_s=0.5, cached=False)
monitor.print_summary()
```

#### ComparisonAnalyzer
- **æ€§èƒ½å°æ¯”åˆ†æ**
- æ¯”è¼ƒå„ªåŒ–å‰å¾Œçš„æŒ‡æ¨™
- é©—è­‰å„ªåŒ–æ•ˆæœ

## æ€§èƒ½ç›®æ¨™

| æŒ‡æ¨™ | ç›®æ¨™ | å¯¦ç¾æ–¹å¼ |
|------|------|----------|
| LLM èª¿ç”¨æ¸›å°‘ | 30%+ | å¿«å– + å»é‡ |
| ç´¢å¼•é€Ÿåº¦æå‡ | 20%+ | æ‰¹æ¬¡è™•ç† + ä¸¦è¡Œ |
| å¿«å–å‘½ä¸­ç‡ | 40%+ | æ™ºèƒ½é›œæ¹Š + å¤šå±¤å¿«å– |
| è¨˜æ†¶é«”ä½¿ç”¨ | ç©©å®š | LRU æ·˜æ±° + å¤§å°é™åˆ¶ |

## ä½¿ç”¨ç¯„ä¾‹

### åŸºæœ¬ä½¿ç”¨

```python
from graphrag_local.optimization import (
    MultiLevelCache,
    AdaptiveBatchProcessor,
    PerformanceMonitor,
)

# åˆå§‹åŒ–
cache = MultiLevelCache()
processor = AdaptiveBatchProcessor(cache=cache)
monitor = PerformanceMonitor()

# è™•ç†
async def process_texts(texts):
    with monitor.track("processing"):
        tasks = [
            processor.process(text, llm_batch_fn)
            for text in texts
        ]
        results = await asyncio.gather(*tasks)
        await processor.flush(llm_batch_fn)

    return results

# æŸ¥çœ‹çµ±è¨ˆ
print(cache.get_stats())
print(processor.get_stats())
monitor.print_summary()
```

### æ•´åˆåˆ°é©é…å™¨

```python
from graphrag_local.adapters import OptimizedLMStudioChatAdapter

adapter = OptimizedLMStudioChatAdapter(
    model_name="qwen/qwen3-4b",
    enable_cache=True,
    enable_batching=True,
)

# ä½¿ç”¨èˆ‡æ¨™æº–é©é…å™¨ç›¸åŒ
response = await adapter.acreate(messages)

# æŸ¥çœ‹å„ªåŒ–æ•ˆæœ
stats = adapter.get_stats()
print(f"Cache hit rate: {stats['cache']['hit_rate']:.1f}%")
```

## é…ç½®æŒ‡å—

### å¿«å–é…ç½®

```yaml
cache:
  type: multilevel
  l1_max_entries: 1000
  l2_max_size_mb: 500
  ttl_seconds: null  # æ°¸ä¸éæœŸ
  cache_dir: .cache/graphrag
```

**èª¿å„ªå»ºè­°**:
- é–‹ç™¼ç’°å¢ƒ: å°å¿«å– (100MB)
- ç”Ÿç”¢ç’°å¢ƒ: å¤§å¿«å– (1GB+)
- ç¢ºå®šæ€§è¼¸å‡º: ç„¡ TTL
- éç¢ºå®šæ€§è¼¸å‡º: è¨­ç½® TTL

### æ‰¹æ¬¡é…ç½®

```yaml
batching:
  min_batch_size: 1
  max_batch_size: 32
  max_wait_time_ms: 100.0
  adaptive_sizing: true
  enable_cache_dedup: true
```

**èª¿å„ªå»ºè­°**:
- é«˜ä¸¦ç™¼: å¤§æ‰¹æ¬¡ (32+)
- ä½ä¸¦ç™¼: å°æ‰¹æ¬¡ (8-16)
- å¿«é€ŸéŸ¿æ‡‰: çŸ­ç­‰å¾…æ™‚é–“ (50ms)
- é«˜åå: é•·ç­‰å¾…æ™‚é–“ (100ms+)

## åŸºæº–æ¸¬è©¦

é‹è¡Œå®Œæ•´åŸºæº–æ¸¬è©¦:

```bash
python graphrag_local/tests/benchmark_phase3.py
```

é æœŸçµæœ:
```
ğŸ“Š Cache Performance:
  Hit Rate: 80%+
  Read Time: < 1ms per item

ğŸš€ Batch Processing:
  Adaptive Batching Speedup: 2.5x+
  Deduplication Savings: 20%+

âš¡ Integrated Optimization:
  LLM Call Reduction: 30%+
  Throughput Improvement: 25%+
```

## æ•…éšœæ’é™¤

### å¿«å–æœªç”Ÿæ•ˆ
- æª¢æŸ¥ `enable_persistence=True`
- ç¢ºèªç›®éŒ„å¯«æ¬Šé™
- é©—è­‰å¿«å–éµä¸€è‡´æ€§

### æ‰¹æ¬¡è™•ç†æ…¢
- æ¸›å°æ‰¹æ¬¡å¤§å°
- å•Ÿç”¨è‡ªé©æ‡‰å¤§å°
- æª¢æŸ¥ I/O ç“¶é ¸

### å…§å­˜ä½¿ç”¨é«˜
- æ¸›å° L1 å¿«å–å¤§å°
- å•Ÿç”¨å¿«å–æ·˜æ±°
- å®šæœŸæ¸…ç†å¿«å–

## API åƒè€ƒ

è©³ç´° API æ–‡æª”è«‹åƒè€ƒå„æ¨¡çµ„çš„ docstring:

```python
help(HashBasedCache)
help(AdaptiveBatchProcessor)
help(PerformanceMonitor)
```

## ä¸‹ä¸€æ­¥

1. é–±è®€ [phase3_optimization_guide.md](../../docs/phase3_optimization_guide.md) ç²å–å®Œæ•´æŒ‡å—
2. é‹è¡ŒåŸºæº–æ¸¬è©¦é©—è­‰æ€§èƒ½
3. æ•´åˆåˆ°ç¾æœ‰ GraphRAG å·¥ä½œæµç¨‹
4. ç›£æ§å’Œèª¿å„ªé…ç½®

## è²¢ç»

æ­¡è¿æäº¤ issue å’Œ PR æ”¹é€²å„ªåŒ–æ¨¡çµ„ï¼

## æˆæ¬Š

èˆ‡ GraphRAG ä¸»é …ç›®ç›¸åŒçš„æˆæ¬Šæ¢æ¬¾ã€‚
