# GraphRAG + LMStudio Phase 2 æ•´åˆ

é€™æ˜¯ GraphRAG èˆ‡ LMStudio çš„ Phase 2 æ ¸å¿ƒæ•´åˆå¯¦ä½œï¼Œå¯¦ç¾äº†å®Œå…¨æœ¬åœ°åŒ–çš„çŸ¥è­˜åœ–è­œæª¢ç´¢å¢å¼·ç”Ÿæˆç³»çµ±ã€‚

## ğŸ“‹ ç›®éŒ„

- [åŠŸèƒ½ç‰¹æ€§](#åŠŸèƒ½ç‰¹æ€§)
- [ç³»çµ±æ¶æ§‹](#ç³»çµ±æ¶æ§‹)
- [å®‰è£æ­¥é©Ÿ](#å®‰è£æ­¥é©Ÿ)
- [å¿«é€Ÿé–‹å§‹](#å¿«é€Ÿé–‹å§‹)
- [é…ç½®èªªæ˜](#é…ç½®èªªæ˜)
- [ä½¿ç”¨ç¯„ä¾‹](#ä½¿ç”¨ç¯„ä¾‹)
- [æ¸¬è©¦](#æ¸¬è©¦)
- [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)

## âœ¨ åŠŸèƒ½ç‰¹æ€§

### Phase 2 æ ¸å¿ƒæ•´åˆå®Œæˆé …ç›®

- âœ… **å·¥å» æ¨¡å¼å¯¦ä½œ** (`factory.py`)
  - çµ±ä¸€çš„ LLM å‰µå»ºä»‹é¢
  - æ”¯æ´å¿«å–å’Œé€Ÿç‡é™åˆ¶è£é£¾å™¨
  - èˆ‡ GraphRAG é…ç½®ç³»çµ±ç„¡ç¸«æ•´åˆ

- âœ… **LMStudio Chat LLM** (`adapters/lmstudio_chat_llm.py`)
  - å®Œæ•´å¯¦ä½œ GraphRAG `BaseLLM` ä»‹é¢
  - æ”¯æ´ JSON æ¨¡å¼è¼¸å‡º
  - èŠå¤©æ­·å²è¨˜éŒ„ç®¡ç†
  - é‡è©¦é‚è¼¯èˆ‡éŒ¯èª¤è™•ç†

- âœ… **LMStudio Embeddings LLM** (`adapters/lmstudio_embeddings_llm.py`)
  - æ–‡æœ¬åµŒå…¥ç”Ÿæˆ
  - æ‰¹æ¬¡è™•ç†æ”¯æ´
  - å‘é‡åŒ–è¡¨ç¤º

- âœ… **GraphRAG é…ç½®ç³»çµ±æ•´åˆ**
  - æ–°å¢ `LLMType.LMStudioChat` æšèˆ‰
  - æ–°å¢ `LLMType.LMStudioEmbedding` æšèˆ‰
  - ä¿®æ”¹ `load_llm.py` æ”¯æ´ LMStudio è¼‰å…¥å™¨
  - æ”¯æ´æ¨™æº– GraphRAG é…ç½®æ ¼å¼

- âœ… **ç«¯å°ç«¯æ¸¬è©¦** (`tests/test_e2e_integration.py`)
  - å–®å…ƒæ¸¬è©¦
  - æ•´åˆæ¸¬è©¦
  - å®Œæ•´ç®¡é“æ¸¬è©¦

## ğŸ—ï¸ ç³»çµ±æ¶æ§‹

```mermaid
graph TB
    User[ä½¿ç”¨è€…] --> Config[GraphRAG Config]
    Config --> LoadLLM[load_llm.py]
    LoadLLM --> Factory[LMStudio Factories]

    Factory --> ChatLLM[LMStudio Chat LLM]
    Factory --> EmbedLLM[LMStudio Embeddings LLM]

    ChatLLM --> Decorators[Decorators<br/>Cache + Rate Limit]
    EmbedLLM --> Decorators

    Decorators --> SDK[LMStudio SDK]
    SDK --> LMStudio[LMStudio Server]
    LMStudio --> Models[Local Models]
```

### æ ¸å¿ƒçµ„ä»¶

1. **é©é…å™¨å±¤** (`adapters/`)
   - `lmstudio_chat_llm.py` - èŠå¤©å®Œæˆé©é…å™¨
   - `lmstudio_embeddings_llm.py` - åµŒå…¥ç”Ÿæˆé©é…å™¨
   - å¯¦ä½œ GraphRAG çš„ `BaseLLM` å”è­°

2. **å·¥å» å±¤** (`lmstudio_factories.py`)
   - å‰µå»ºé…ç½®å®Œæ•´çš„ LLM å¯¦ä¾‹
   - æ‡‰ç”¨è£é£¾å™¨ï¼ˆå¿«å–ã€é€Ÿç‡é™åˆ¶ï¼‰
   - æä¾›çµ±ä¸€çš„å‰µå»ºä»‹é¢

3. **é…ç½®æ•´åˆ**
   - `graphrag/config/enums.py` - æ–°å¢ LMStudio æšèˆ‰
   - `graphrag/index/llm/load_llm.py` - è¼‰å…¥å™¨è¨»å†Š

## ğŸ”§ å®‰è£æ­¥é©Ÿ

### 1. å‰ç½®éœ€æ±‚

```bash
# Python 3.10+
python --version

# LMStudio æ‡‰ç”¨ç¨‹å¼
# ä¸‹è¼‰è‡ª: https://lmstudio.ai/
```

### 2. å®‰è£ä¾è³´

```bash
# å®‰è£ GraphRAG
cd /path/to/graphrag
pip install -e .

# å®‰è£ LMStudio SDK
pip install lmstudio

# å®‰è£æ¸¬è©¦ä¾è³´ï¼ˆå¯é¸ï¼‰
pip install pytest pytest-asyncio
```

### 3. é…ç½® LMStudio

1. å•Ÿå‹• LMStudio æ‡‰ç”¨ç¨‹å¼
2. ä¸‹è¼‰ä¸¦è¼‰å…¥æ¨¡å‹ï¼š
   - **Chat æ¨¡å‹**: `qwen/qwen3-4b-2507` æˆ–é¡ä¼¼
   - **Embedding æ¨¡å‹**: `nomic-embed-text-v1.5` æˆ–é¡ä¼¼
3. ç¢ºä¿æ¨¡å‹åœ¨ LMStudio ä¸­å·²å®Œå…¨è¼‰å…¥

## ğŸš€ å¿«é€Ÿé–‹å§‹

### æ­¥é©Ÿ 1: å‰µå»ºé…ç½®æ–‡ä»¶

å‰µå»º `settings.yaml`:

```yaml
llm:
  type: lmstudio_chat
  model: "qwen/qwen3-4b-2507"
  temperature: 0.0
  max_tokens: 4000
  model_supports_json: true

embeddings:
  llm:
    type: lmstudio_embedding
    model: "nomic-embed-text-v1.5"

# å…¶ä»–é…ç½®...
```

æˆ–ä½¿ç”¨æä¾›çš„ç¯„ä¾‹é…ç½®ï¼š

```bash
cp graphrag_local/config/phase2_settings.yaml ./settings.yaml
```

### æ­¥é©Ÿ 2: æº–å‚™è¼¸å…¥æ•¸æ“š

```bash
mkdir -p input
echo "GraphRAG is a knowledge graph system..." > input/sample.txt
```

### æ­¥é©Ÿ 3: åˆå§‹åŒ– GraphRAG

```bash
graphrag init --root .
```

### æ­¥é©Ÿ 4: åŸ·è¡Œç´¢å¼•

```bash
graphrag index --root .
```

### æ­¥é©Ÿ 5: æŸ¥è©¢çŸ¥è­˜åœ–è­œ

```bash
# å…¨åŸŸæŸ¥è©¢
graphrag query \
  --root . \
  --method global \
  --query "What is GraphRAG?"

# å±€éƒ¨æŸ¥è©¢
graphrag query \
  --root . \
  --method local \
  --query "How does entity extraction work?"
```

## âš™ï¸ é…ç½®èªªæ˜

### LLM é…ç½®åƒæ•¸

```yaml
llm:
  type: lmstudio_chat              # å¿…å¡«: LLM é¡å‹
  model: "qwen/qwen3-4b-2507"      # å¿…å¡«: æ¨¡å‹æ¨™è­˜ç¬¦
  temperature: 0.0                  # å¯é¸: æº«åº¦åƒæ•¸ (0.0-2.0)
  max_tokens: 4000                  # å¯é¸: æœ€å¤§ç”Ÿæˆä»¤ç‰Œæ•¸
  top_p: 1.0                        # å¯é¸: Nucleus sampling
  model_supports_json: true         # å¯é¸: JSON æ¨¡å¼æ”¯æ´
  concurrent_requests: 4            # å¯é¸: ä¸¦ç™¼è«‹æ±‚æ•¸
```

### Embedding é…ç½®åƒæ•¸

```yaml
embeddings:
  llm:
    type: lmstudio_embedding       # å¿…å¡«: Embedding é¡å‹
    model: "nomic-embed-text-v1.5" # å¿…å¡«: æ¨¡å‹æ¨™è­˜ç¬¦

  batch_size: 16                    # å¯é¸: æ‰¹æ¬¡å¤§å°
  batch_max_tokens: 8191            # å¯é¸: æ‰¹æ¬¡æœ€å¤§ä»¤ç‰Œæ•¸
```

### æ•ˆèƒ½èª¿æ•´åƒæ•¸

```yaml
# ä¸¦è¡Œè™•ç†
parallelization:
  num_threads: 4      # è™•ç†åŸ·è¡Œç·’æ•¸ï¼ˆæ ¹æ“š CPU èª¿æ•´ï¼‰
  stagger: 0.5        # åŸ·è¡Œç·’å•Ÿå‹•å»¶é²ï¼ˆç§’ï¼‰

# å¯¦é«”æå–
entity_extraction:
  max_gleanings: 2    # é™ä½ä»¥æå‡æœ¬åœ°æ¨¡å‹é€Ÿåº¦

# æ–‡æœ¬åˆ†å¡Š
chunks:
  size: 1200          # åˆ†å¡Šå¤§å°
  overlap: 100        # é‡ç–Šå¤§å°
```

## ğŸ’¡ ä½¿ç”¨ç¯„ä¾‹

### ç¯„ä¾‹ 1: åŸºæœ¬æ–‡æœ¬å®Œæˆ

```python
from graphrag_local.lmstudio_factories import create_lmstudio_chat_llm

# å‰µå»º LLM
config = {
    "model": "qwen/qwen3-4b-2507",
    "temperature": 0.0,
}
llm = create_lmstudio_chat_llm(config)

# ç”Ÿæˆå›æ‡‰
result = await llm(
    "What is a knowledge graph?",
    name="example_query"
)
print(result.output)
```

### ç¯„ä¾‹ 2: JSON æ¨¡å¼è¼¸å‡º

```python
from graphrag_local.adapters.lmstudio_chat_llm import (
    LMStudioChatLLM,
    LMStudioConfiguration,
)

# é…ç½® JSON æ¨¡å¼
config = LMStudioConfiguration({
    "model": "qwen/qwen3-4b-2507",
    "temperature": 0.0,
    "model_supports_json": True,
})
llm = LMStudioChatLLM(config)

# æå–çµæ§‹åŒ–æ•¸æ“š
prompt = """Extract entities from: "Microsoft was founded by Bill Gates."
Return as JSON: {"entities": [{"name": "...", "type": "..."}]}
"""

result = await llm(prompt, json=True, name="entity_extraction")
print(result.json)  # {"entities": [{"name": "Microsoft", "type": "ORGANIZATION"}, ...]}
```

### ç¯„ä¾‹ 3: æ–‡æœ¬åµŒå…¥

```python
from graphrag_local.lmstudio_factories import create_lmstudio_embedding_llm

# å‰µå»º Embedding LLM
config = {"model": "nomic-embed-text-v1.5"}
embedder = create_lmstudio_embedding_llm(config)

# ç”ŸæˆåµŒå…¥
result = await embedder(
    "GraphRAG combines knowledge graphs with retrieval.",
    name="embed_text"
)
embedding_vector = result.output[0]  # List[float]
print(f"Embedding dimension: {len(embedding_vector)}")
```

### ç¯„ä¾‹ 4: å¾ GraphRAG é…ç½®å‰µå»º

```python
from graphrag.config import create_graphrag_config
from graphrag_local.factory import create_lmstudio_llm_from_graphrag_config

# åŠ è¼‰ GraphRAG é…ç½®
config = create_graphrag_config(root_dir=".")

# å‰µå»º LLM
llm = create_lmstudio_llm_from_graphrag_config(config)

# ä½¿ç”¨ LLM
result = await llm("Hello!", name="greeting")
print(result.output)
```

## ğŸ§ª æ¸¬è©¦

### é‹è¡Œæ‰€æœ‰æ¸¬è©¦

```bash
cd graphrag_local
pytest tests/test_e2e_integration.py -v -s
```

### é‹è¡Œç‰¹å®šæ¸¬è©¦

```bash
# æ¸¬è©¦èŠå¤© LLM
pytest tests/test_e2e_integration.py::TestLMStudioChatLLM -v -s

# æ¸¬è©¦åµŒå…¥ LLM
pytest tests/test_e2e_integration.py::TestLMStudioEmbeddingsLLM -v -s

# æ¸¬è©¦é…ç½®æ•´åˆ
pytest tests/test_e2e_integration.py::TestGraphRAGConfigIntegration -v -s

# å®Œæ•´ç«¯å°ç«¯æ¸¬è©¦
pytest tests/test_e2e_integration.py::TestEndToEndPipeline -v -s
```

### æ¸¬è©¦è¦†è“‹ç¯„åœ

- âœ… åŸºæœ¬æ–‡æœ¬å®Œæˆ
- âœ… èŠå¤©æ­·å²æ”¯æ´
- âœ… JSON æ¨¡å¼è¼¸å‡º
- âœ… å–®ä¸€æ–‡æœ¬åµŒå…¥
- âœ… æ‰¹æ¬¡æ–‡æœ¬åµŒå…¥
- âœ… å·¥å» å‡½æ•¸
- âœ… é…ç½®æ•´åˆ
- âœ… å®Œæ•´ç®¡é“æµç¨‹

## ğŸ” æ•…éšœæ’é™¤

### å•é¡Œ 1: ImportError: No module named 'lmstudio'

**è§£æ±ºæ–¹æ¡ˆ**:
```bash
pip install lmstudio
```

### å•é¡Œ 2: RuntimeError: Failed to load LMStudio model

**åŸå› **: LMStudio æœªé‹è¡Œæˆ–æ¨¡å‹æœªè¼‰å…¥

**è§£æ±ºæ–¹æ¡ˆ**:
1. å•Ÿå‹• LMStudio æ‡‰ç”¨ç¨‹å¼
2. åœ¨ LMStudio GUI ä¸­è¼‰å…¥æ¨¡å‹
3. ç¢ºèªæ¨¡å‹åç¨±èˆ‡é…ç½®ä¸­çš„ä¸€è‡´

### å•é¡Œ 3: ç´¢å¼•éç¨‹è¨˜æ†¶é«”ä¸è¶³

**è§£æ±ºæ–¹æ¡ˆ**:
```yaml
# åœ¨ settings.yaml ä¸­èª¿æ•´
chunks:
  size: 800  # æ¸›å°åˆ†å¡Šå¤§å°

entity_extraction:
  max_gleanings: 1  # æ¸›å°‘æå–è¼ªæ¬¡

parallelization:
  num_threads: 2  # æ¸›å°‘ä¸¦è¡ŒåŸ·è¡Œç·’
```

### å•é¡Œ 4: JSON è§£æå¤±æ•—

**è§£æ±ºæ–¹æ¡ˆ**:
```yaml
llm:
  model_supports_json: false  # å¦‚æœæ¨¡å‹ä¸æ”¯æ´åŸç”Ÿ JSON æ¨¡å¼
```

ç³»çµ±æœƒè‡ªå‹•å›é€€åˆ°æ‰‹å‹• JSON è§£æã€‚

### å•é¡Œ 5: é€Ÿåº¦éæ…¢

**å„ªåŒ–å»ºè­°**:

1. **ä½¿ç”¨é‡åŒ–æ¨¡å‹**: é¸æ“‡ Q4 æˆ– Q5 é‡åŒ–ç‰ˆæœ¬
2. **å•Ÿç”¨ GPU åŠ é€Ÿ**: åœ¨ LMStudio ä¸­ç¢ºä¿ä½¿ç”¨ GPU
3. **æ¸›å°‘ä¸¦è¡Œåº¦**:
   ```yaml
   parallelization:
     num_threads: 2
   ```
4. **å¢åŠ æ‰¹æ¬¡å¤§å°**:
   ```yaml
   embeddings:
     batch_size: 32
   ```

## ğŸ“Š æ•ˆèƒ½åŸºæº–

### ç¡¬é«”é…ç½®

- **CPU**: Apple M2 Pro
- **RAM**: 16GB
- **GPU**: M2 Pro é›†æˆ GPU

### ç´¢å¼•æ•ˆèƒ½

- **æ–‡æª”å¤§å°**: 10,000 å­—
- **ç´¢å¼•æ™‚é–“**: ~15 åˆ†é˜
- **è¨˜æ†¶é«”ä½¿ç”¨**: ~4GB
- **æ¨¡å‹**: Qwen3-4B Q4 é‡åŒ–

### æŸ¥è©¢æ•ˆèƒ½

- **å…¨åŸŸæŸ¥è©¢**: ~5-10 ç§’
- **å±€éƒ¨æŸ¥è©¢**: ~2-5 ç§’

## ğŸ›£ï¸ è·¯ç·šåœ–

### Phase 3: æ•ˆèƒ½å„ªåŒ–ï¼ˆè¨ˆåŠƒä¸­ï¼‰
- [ ] æ‰¹æ¬¡è™•ç†å„ªåŒ–
- [ ] å¯¦é«”å¿«å–æ©Ÿåˆ¶
- [ ] é—œä¿‚æå–åŠ é€Ÿ
- [ ] è¨˜æ†¶é«”æ± ç®¡ç†

### Phase 4: ç³»çµ±æ•´åˆï¼ˆè¨ˆåŠƒä¸­ï¼‰
- [ ] Kotaemon UI æ•´åˆ
- [ ] Docker å®¹å™¨åŒ–éƒ¨ç½²
- [ ] ç›£æ§èˆ‡æ—¥èªŒç³»çµ±
- [ ] API æœå‹™åŒ…è£

## ğŸ“ è¨±å¯è­‰

æœ¬å°ˆæ¡ˆéµå¾ª GraphRAG çš„ MIT è¨±å¯è­‰ã€‚

## ğŸ¤ è²¢ç»

æ­¡è¿æäº¤ Pull Request å’Œ Issueï¼

## ğŸ“§ è¯çµ¡

å¦‚æœ‰å•é¡Œæˆ–å»ºè­°ï¼Œè«‹æäº¤ GitHub Issueã€‚

---

**Phase 2 å¯¦ä½œå®Œæˆ** âœ…

æœ¬æ•´åˆå¯¦ç¾äº† GraphRAG èˆ‡ LMStudio çš„æ·±åº¦æ•´åˆï¼Œè®“æ‚¨èƒ½å¤ å®Œå…¨åœ¨æœ¬åœ°ç’°å¢ƒä¸­é‹è¡ŒçŸ¥è­˜åœ–è­œæª¢ç´¢ç³»çµ±ï¼Œç„¡éœ€ä¾è³´ä»»ä½•é›²ç«¯ API æœå‹™ã€‚
