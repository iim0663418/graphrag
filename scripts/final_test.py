#!/usr/bin/env python3
"""
GraphRAG å®Œæ•´æ¸¬è©¦è…³æœ¬ - ä¿®å¾©ç‰ˆæœ¬
"""

import os
import sys
import asyncio
import shutil

# è¨­ç½®è·¯å¾‘
sys.path.insert(0, '..')

async def run_graphrag_index():
    """é‹è¡Œ GraphRAG ç´¢å¼•"""
    print("ğŸš€ GraphRAG å®Œæ•´ç´¢å¼•æ¸¬è©¦")
    print("=" * 30)
    
    try:
        from graphrag.config import create_graphrag_config
        from graphrag.index.input import load_input
        from graphrag.index.run import run_pipeline_with_config
        
        # 1. å‰µå»ºä¸¦ä¿®å¾©é…ç½®
        config = create_graphrag_config(root_dir='.')
        
        # å¼·åˆ¶ä¿®å¾©æ–‡ä»¶æ¨¡å¼
        config.input.file_pattern = r'.*\.txt$'
        
        print(f"é…ç½®æª¢æŸ¥:")
        print(f"  LLM: {config.llm.model} @ {config.llm.api_base}")
        print(f"  Embedding: {config.embeddings.llm.model}")
        print(f"  æ–‡ä»¶æ¨¡å¼: {config.input.file_pattern}")
        
        # 2. æ¸¬è©¦è¼¸å…¥åŠ è¼‰
        print("\nğŸ“ åŠ è¼‰è¼¸å…¥æ•¸æ“š...")
        input_data = await load_input(config.input)
        print(f"âœ… æˆåŠŸåŠ è¼‰ {len(input_data)} å€‹æ–‡æª”")
        
        if len(input_data) == 0:
            print("âŒ æ²’æœ‰æ‰¾åˆ°è¼¸å…¥æ–‡æª”")
            return False
        
        first_doc = input_data.iloc[0]
        print(f"   ç¬¬ä¸€å€‹æ–‡æª”: {len(first_doc.text)} å­—ç¬¦")
        
        # 3. æ¸¬è©¦ API é€£æ¥
        print("\nğŸ”— æ¸¬è©¦ API é€£æ¥...")
        from openai import OpenAI
        client = OpenAI(api_key='lm-studio', base_url='http://localhost:1234/v1')
        
        # æ¸¬è©¦ LLM
        llm_response = client.chat.completions.create(
            model='qwen/qwen3-4b-2507',
            messages=[{'role': 'user', 'content': 'Hello'}],
            max_tokens=5
        )
        print("âœ… LLM é€£æ¥æ­£å¸¸")
        
        # æ¸¬è©¦ Embedding
        embed_response = client.embeddings.create(
            model='nomic-embed-text-v1.5',
            input='test'
        )
        print("âœ… Embedding é€£æ¥æ­£å¸¸")
        
        # 4. æ¸…ç†ä¸¦é‹è¡Œç´¢å¼•
        print("\nğŸ”„ é–‹å§‹ç´¢å¼•...")
        
        if os.path.exists('output'):
            shutil.rmtree('output')
            print("ğŸ§¹ æ¸…ç†èˆŠè¼¸å‡º")
        
        # é‹è¡Œç´¢å¼•
        results = []
        async for result in run_pipeline_with_config(config):
            results.append(result)
        
        print("âœ… ç´¢å¼•å®Œæˆ")
        
        # 5. æª¢æŸ¥çµæœ
        output_files = []
        total_size = 0
        
        if os.path.exists('output'):
            for root, dirs, files in os.walk('output'):
                for f in files:
                    full_path = os.path.join(root, f)
                    size = os.path.getsize(full_path)
                    output_files.append((f, size))
                    total_size += size
        
        print(f"\nğŸ“Š ç´¢å¼•çµæœ:")
        print(f"   æ–‡ä»¶æ•¸é‡: {len(output_files)}")
        print(f"   ç¸½å¤§å°: {total_size:,} bytes")
        
        if output_files:
            print("\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
            # æŒ‰å¤§å°æ’åº
            sorted_files = sorted(output_files, key=lambda x: x[1], reverse=True)
            for name, size in sorted_files[:10]:
                print(f"   {name}: {size:,} bytes")
            
            # æª¢æŸ¥é—œéµæ–‡ä»¶
            key_patterns = ['entities', 'relationships', 'communities']
            found_patterns = []
            
            for pattern in key_patterns:
                matching_files = [f for f, _ in output_files if pattern in f.lower()]
                if matching_files:
                    found_patterns.append(pattern)
            
            print(f"\nğŸ¯ æ‰¾åˆ°é—œéµçµ„ä»¶: {found_patterns}")
            
            if len(found_patterns) >= 2:
                print("\nğŸ‰ GraphRAG ç´¢å¼•æˆåŠŸï¼")
                print("âœ… çŸ¥è­˜åœ–è­œå·²æ§‹å»º")
                print("âœ… æœ¬åœ° LMStudio æ¨¡å‹å·¥ä½œæ­£å¸¸")
                return True
            else:
                print("\nâš ï¸  ç´¢å¼•éƒ¨åˆ†æˆåŠŸ")
                return True
        else:
            print("\nâŒ æ²’æœ‰ç”Ÿæˆè¼¸å‡ºæ–‡ä»¶")
            return False
            
    except Exception as e:
        print(f"\nâŒ ç´¢å¼•å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = asyncio.run(run_graphrag_index())
    
    if success:
        print("\n" + "="*50)
        print("ğŸ‰ GraphRAG + LMStudio é›†æˆæ¸¬è©¦æˆåŠŸï¼")
        print("âœ… æœ¬åœ°åŒ– GraphRAG è§£æ±ºæ–¹æ¡ˆå·²é©—è­‰")
        print("âœ… é›¶æˆæœ¬çŸ¥è­˜åœ–è­œæ§‹å»ºå·²å¯¦ç¾")
        print("="*50)
    else:
        print("\n" + "="*50)
        print("âŒ æ¸¬è©¦æœªå®Œå…¨æˆåŠŸ")
        print("ğŸ’¡ è«‹æª¢æŸ¥ LMStudio ç‹€æ…‹å’Œæ¨¡å‹åŠ è¼‰")
        print("="*50)
    
    sys.exit(0 if success else 1)
