#!/usr/bin/env python3
"""
GraphRAG å•é¡Œè¨ºæ–·è…³æœ¬
"""

import os
import sys
import logging

# è¨­ç½®è·¯å¾‘
sys.path.insert(0, '..')

def test_basic_functionality():
    """æ¸¬è©¦åŸºæœ¬åŠŸèƒ½"""
    print("ğŸ” GraphRAG åŸºæœ¬åŠŸèƒ½æ¸¬è©¦")
    print("=" * 30)
    
    try:
        # 1. æ¸¬è©¦é…ç½®åŠ è¼‰
        from graphrag.config import create_graphrag_config
        config = create_graphrag_config(root_dir='.')
        
        print("âœ… é…ç½®åŠ è¼‰æˆåŠŸ")
        print(f"   LLM: {config.llm.model}")
        print(f"   Embedding: {config.embeddings.llm.model}")
        
        # 2. æ¸¬è©¦è¼¸å…¥æ–‡ä»¶
        input_files = []
        if os.path.exists('input'):
            for f in os.listdir('input'):
                if f.endswith('.txt'):
                    path = os.path.join('input', f)
                    size = os.path.getsize(path)
                    input_files.append((f, size))
        
        print(f"âœ… è¼¸å…¥æ–‡ä»¶: {len(input_files)} å€‹")
        for name, size in input_files:
            print(f"   {name}: {size} bytes")
        
        # 3. æ¸¬è©¦ API é€£æ¥
        from openai import OpenAI
        client = OpenAI(api_key='lm-studio', base_url='http://localhost:1234/v1')
        
        # æ¸¬è©¦ LLM
        try:
            response = client.chat.completions.create(
                model='qwen/qwen3-4b-2507',
                messages=[{'role': 'user', 'content': 'Hello'}],
                max_tokens=5
            )
            print("âœ… LLM é€£æ¥æ­£å¸¸")
        except Exception as e:
            print(f"âŒ LLM é€£æ¥å¤±æ•—: {e}")
            return False
        
        # æ¸¬è©¦ Embedding
        try:
            embed_response = client.embeddings.create(
                model='nomic-embed-text-v1.5',
                input='test'
            )
            print("âœ… Embedding é€£æ¥æ­£å¸¸")
        except Exception as e:
            print(f"âŒ Embedding é€£æ¥å¤±æ•—: {e}")
            return False
        
        # 4. å˜—è©¦æœ€å°åŒ–ç´¢å¼•
        print("\nğŸ”„ å˜—è©¦æœ€å°åŒ–ç´¢å¼•...")
        
        # è¨­ç½®ç°¡å–®æ—¥èªŒ
        logging.basicConfig(level=logging.INFO)
        
        from graphrag.index.run import run_pipeline_with_config
        
        # æ¸…ç†è¼¸å‡ºç›®éŒ„
        import shutil
        if os.path.exists('output'):
            shutil.rmtree('output')
        
        # é‹è¡Œç´¢å¼•
        result = run_pipeline_with_config(config)
        
        # æª¢æŸ¥çµæœ
        output_files = []
        if os.path.exists('output'):
            for root, dirs, files in os.walk('output'):
                output_files.extend(files)
        
        print(f"ğŸ“Š ç”Ÿæˆæ–‡ä»¶: {len(output_files)} å€‹")
        
        if output_files:
            print("âœ… ç´¢å¼•æˆåŠŸï¼")
            for f in output_files[:5]:
                print(f"   {f}")
            return True
        else:
            print("âŒ ç´¢å¼•æœªç”Ÿæˆè¼¸å‡º")
            return False
            
    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_basic_functionality()
    sys.exit(0 if success else 1)
